import json
import os
import pandas as pd
from datetime import datetime

def fmt_c(x): return f"Â¥{x:,.1f}" if pd.notnull(x) else "-"
def fmt_p(x): return f"{x:.1%}" if pd.notnull(x) else "-"
def fmt_f(x): return f"{x:.2f}" if pd.notnull(x) else "-"

class StrategicReporter:
    def __init__(self, channel_name, data, global_benchmarks=None):
        self.ch = channel_name
        self.data = data
        self.benchmarks = global_benchmarks or {}
        self.lines = []
        
    def add_header(self, text, level=1):
        self.lines.append(f"{ '#' * level} {text}\n")
        
    def add_quote(self, text):
        self.lines.append(f"> {text}\n")
        
    def add_table(self, headers, rows):
        self.lines.append("| " + " | ".join(headers) + " |")
        self.lines.append("| " + " | ".join(['---'] * len(headers)) + " |")
        for row in rows:
            self.lines.append("| " + " | ".join([str(r) for r in row]) + " |")
        self.lines.append("")

    def render_overview(self):
        bo = self.data['business_overview']
        self.add_header("1. æ•´ä½“ä¸šåŠ¡æ•ˆæœå‘ˆç°", 2)
        
        aov_bench = self.benchmarks.get('aov_avg', 0)
        upt_bench = self.benchmarks.get('upt_avg', 0)
        aov_ctx, upt_ctx = "", ""
        
        if self.ch != "å…¨æ¸ é“æ€»è§ˆ" and aov_bench > 0:
            a_diff = (bo['aov'] - aov_bench) / aov_bench
            u_diff = (bo['upt'] - upt_bench) / upt_bench
            aov_ctx = f" ({'+' if a_diff>0 else ''}{fmt_p(a_diff)})"
            upt_ctx = f" ({'+' if u_diff>0 else ''}{fmt_p(u_diff)})"
            
        row_data = [
            fmt_c(bo['gmv_total']), bo['order_total'], fmt_f(bo['daily_avg_orders']), 
            bo['active_skus'], fmt_p(bo['discount_rate']), fmt_p(bo['promo_penetration']), 
            fmt_p(bo.get('sku_promo_penetration', 0)),
            fmt_c(bo['aov']) + aov_ctx, fmt_f(bo['upt']) + upt_ctx
        ]
        self.add_table(["GMV", "è®¢å•æ€»æ•°", "æ—¥å‡å•é‡", "åŠ¨é”€SKU", "æŠ˜æ‰£ç‡", "è®¢å•ä¿ƒé”€æ¸—é€", "å•†å“ä¿ƒé”€æ¸—é€", "å®¢å•ä»·", "å®¢ä»¶æ•°"], [row_data])

    def render_product_efficiency(self):
        pe = self.data['product_efficiency']
        self.add_header("2. å•†å“æ•ˆç‡å‘ˆç° (æ¸—é€-å¸¦åŠ¨çŸ©é˜µ)", 2)
        pa = pe['penetration_affinity']
        if 'quadrants' in pa:
            bench = pa.get('benchmarks', {})
            self.add_quote(
                "**æŒ‡æ ‡è¯¦è§£ (Glossary)**:<br>"
                "- **æ¸—é€ç‡**: `å«è¯¥å•†å“è®¢å•æ•° / æ€»è®¢å•æ•°`ã€‚ä»£è¡¨æµé‡è·å–èƒ½åŠ›ã€‚<br>"
                "- **å¸¦åŠ¨ç³»æ•°**: `è¯¥å•†å“æ‰€åœ¨è®¢å•å¹³å‡ä»¶æ•° - 1`ã€‚ä»£è¡¨è¿å¸¦èƒ½åŠ›ã€‚<br>"
                "- **è§’è‰²å®šä¹‰**: **Hooks (é’©å­)**: é«˜æ¸—é€+é«˜å¸¦åŠ¨ï¼›**Islands (å­¤å²›)**: é«˜æ¸—é€+ä½å¸¦åŠ¨ï¼›**Assassins (åˆºå®¢)**: ä½ä»·+ä½å¸¦åŠ¨ã€‚"
            )
            self.add_quote(f"**åŠ¨æ€é˜ˆå€¼è¯´æ˜**: æ¸—é€Top20%={fmt_p(bench.get('p_threshold',0))}, å¸¦åŠ¨å‡å€¼={fmt_f(bench.get('a_threshold',0))}")
            
            rows = []
            for k in ['Hooks', 'Bundlers', 'Islands', 'Assassins']:
                for item in pa['quadrants'].get(k, [])[:5]:
                    rows.append([item['sku'], fmt_p(item['penetration']), fmt_f(item['affinity']), fmt_c(item['avg_price']), k])
            self.add_table(["å•†å“åç§°", "æ¸—é€ç‡", "å¸¦åŠ¨ç³»æ•°", "ä»¶å•ä»·", "æˆ˜ç•¥è§’è‰²"], rows)
            
            assassin_count = len(pa['quadrants'].get('Assassins', []))
            if assassin_count > 0:
                self.add_quote(f"ğŸ’¡ **ç»è¥è¯Šæ–­**: å‘ç° {assassin_count} ä¸ªâ€˜å±¥çº¦åˆºå®¢â€™å•†å“ã€‚å»ºè®®é€šè¿‡æ†ç»‘é”€å”®æˆ–æå‡èµ·è´­é‡æ¥å¯¹å†²é…é€æˆæœ¬ã€‚")

    def render_pricing_efficiency(self):
        pe = self.data['pricing_efficiency']
        self.add_header("3. ä»·æ ¼ä¸ä¿ƒé”€æ•ˆç‡å‘ˆç°", 2)
        
        sk = pe['skewness']
        self.add_header("3.1 è®¢å•ä»·æ ¼å¸¦åæ€åˆ†æ", 3)
        self.add_quote("**æŒ‡æ ‡è¯¦è§£**: åæ€ç³»æ•°è¡¡é‡å®¢å•ä»·åˆ†å¸ƒçš„ä¸å¯¹ç§°æ€§ã€‚æ­£åè¶Šå¤§ï¼Œè¯´æ˜ä½å®¢å•è®¢å•å æ¯”è¶Šé«˜ã€‚")
        row_sk = [fmt_c(sk['mean']), fmt_c(sk['median']), fmt_c(sk.get('mode', 0)), fmt_f(sk['skewness_index']), sk['diagnosis']]
        self.add_table(["å‡å€¼", "ä¸­ä½æ•°", "ä¼—æ•°", "åæ€ç³»æ•°", "è¯Šæ–­"], [row_sk])
        
        el = pe['elasticity']
        self.add_header("3.2 ä»·æ ¼ç¨³å®šæ€§å®¡è®¡ä¸æŠ˜æ‰£å¼¹æ€§", 3)
        audit = el.get('audit', {})
        if audit:
            self.add_quote(f"**ä»·æ ¼ç¨³å®šæ€§å®¡è®¡**: å§‹ç»ˆåŸä»·é”€å”®å•†å“ {audit['always_full_price_count']}ä¸ª, å§‹ç»ˆä¿ƒé”€å•†å“ {audit['always_promo_count']}ä¸ªã€‚")
        
        has_data = False
        if el.get('inelastic_skus'):
            self.add_header("âŒ æŠ˜æ‰£é»‘æ¦œï¼šæ— å¼¹æ€§/ä½æ•æ„Ÿ (Top 10)", 4)
            self.add_quote("è¯Šæ–­ï¼šæ­¤ç±»å•†å“æ‰“æŠ˜æ— é”€é‡å¢é‡ï¼Œçº¯ç²¹æŸå¤±æ¯›åˆ©ã€‚")
            self.add_table(["å•†å“åç§°"], [[s] for s in el['inelastic_skus'][:10]])
            has_data = True
        if el.get('elastic_skus'):
            self.add_header("âœ… æŠ˜æ‰£çº¢æ¦œï¼šé«˜å¼¹æ€§/é«˜æ•æ„Ÿ (Top 10)", 4)
            self.add_quote("è¯Šæ–­ï¼šæ­¤ç±»å•†å“å¯¹ä¿ƒé”€æåº¦æ•æ„Ÿï¼Œå»ºè®®ä½œä¸ºå¼•æµä¸»æ‰“ã€‚")
            self.add_table(["å•†å“åç§°"], [[s] for s in el['elastic_skus'][:10]])
            has_data = True
        if not has_data:
            self.add_quote("âš ï¸ **å®¢è§‚ç»“è®º**: è§‚æµ‹æœŸå†…ç»å¤§å¤šæ•°å•†å“ä»·æ ¼æœªå˜åŠ¨ï¼Œæ— æ³•è¿›è¡Œæœ‰æ•ˆçš„æŠ˜æ‰£å¼¹æ€§æµ‹ç®—ã€‚")

    def render_spatio_temporal(self):
        st = self.data['spatio_temporal']
        self.add_header("4. æ—¶ç©ºç”Ÿæ´»åµŒå…¥å‘ˆç°", 2)
        ov = st.get('overview', {})
        if ov:
            self.add_header("4.1 æ—¶ç©ºåŸºç¡€åˆ†å¸ƒ (Overview)", 3)
            day_rows = [[d['day_type'], d['æµæ°´å•å·'], fmt_c(d['å®æ”¶é‡‘é¢']), fmt_p(d['order_share'])] for d in ov['day_distribution']]
            self.add_table(["æ—¥ç±»å‹", "è®¢å•é‡", "GMV", "å æ¯”"], day_rows)
            per_rows = [[p['period'], p['æµæ°´å•å·'], fmt_c(p['å®æ”¶é‡‘é¢']), fmt_p(p['order_share'])] for p in ov['period_distribution']]
            self.add_table(["æ—¶æ®µ", "è®¢å•é‡", "GMV", "å æ¯”"], per_rows)
        
        fl = st['fluctuation']
        self.add_header("4.2 å¼‚åŠ¨ç³»æ•°", 3)
        self.add_quote("**æŒ‡æ ‡è¯¦è§£**: å¼‚åŠ¨ç³»æ•° > 1.2 é€šå¸¸ä»£è¡¨ç¤¾åŒº/ç”Ÿæ´»å‹å•†åœˆç‰¹å¾ã€‚")
        row_fl = ["å‘¨æœ«", fmt_f(fl['weekend_coef']), "ç”Ÿæ´»å‹" if fl['weekend_coef']>1.2 else "åŠå…¬å‹"]
        self.add_table(["ç±»å‹", "å¼‚åŠ¨ç³»æ•°", "å•†åœˆæ¨æ–­"], [row_fl])
        
        self.add_header("4.3 TGI æ—¶æ®µå¿ƒæ™ºå•†å“", 3)
        self.add_quote("**æŒ‡æ ‡è¯¦è§£**: TGI > 100 ä»£è¡¨è¯¥æ—¶æ®µå¯¹è¯¥å“ç±»æœ‰æ˜¾è‘—åå¥½ã€‚")
        tgi_rows = []
        for p, items in st['tgi_heatmap'].items():
            item_str = ", ".join([f"{i['sku']}({i['tgi']:.0f})" for i in items])
            tgi_rows.append([p, item_str])
        self.add_table(["æ—¶æ®µ", "é«˜ TGI å•†å“ (Top 3)"], tgi_rows)

    def render_basket(self):
        bf = self.data['basket_features']
        self.add_header("5. è´­ç‰©ç¯®ç‰¹å¾å‘ˆç°", 2)
        
        orphan = bf['orphan_orders']
        self.add_header("5.1 å­¤å„¿å•è¯Šæ–­", 3)
        self.add_quote("**æŒ‡æ ‡è¯¦è§£**: å­¤å„¿å•å³ä»…å«1ä»¶å•†å“çš„è®¢å•ï¼Œä»£è¡¨æé«˜çš„å±¥çº¦æˆæœ¬å æ¯”ã€‚")
        self.lines.append(f"**å­¤å„¿å•å æ¯”**: {fmt_p(orphan['ratio'])}\n")
        if orphan['culprits']:
            self.add_header("å­¤å„¿å•å…ƒå‡¶ Top 10", 4)
            self.add_table(["å•†å“åç§°", "å æ¯”"], [[k, fmt_p(v)] for k,v in list(orphan['culprits'].items())[:10]])
        
        self.add_header("5.2 è´­ç‰©ç¯®å¤æ‚åº¦èšç±»", 3)
        self.add_quote("**æŒ‡æ ‡è¯¦è§£**: åŸºäºä»¶æ•°ã€ç±»ç›®æ•°ã€é‡‘é¢è¿›è¡Œèšç±»ï¼Œè¿˜åŸç”¨æˆ·è´­ä¹°æŒ‡çº¹ã€‚")
        rows = []
        for seg in bf['complexity_clusters']:
            ft = seg['features']
            rows.append([seg['label'], fmt_p(seg['share']), fmt_f(ft['items']), fmt_f(ft['categories']), fmt_c(ft['aov'])])
        self.add_table(["æŒ‡çº¹ç±»å‹", "å æ¯”", "å¹³å‡ä»¶æ•°", "è·¨ç±»ç›®æ•°", "å¹³å‡å®¢å•"], rows)

    def generate(self):
        self.lines.append(f"# å…¨é“¾è·¯ç»è¥è¯Šæ–­æŠ¥å‘Š: {self.ch}\n")
        self.lines.append(f"> åˆ†ææ¨¡å¼: ç»Ÿè®¡è‡ªé€‚åº” | è¯Šæ–­çº§åˆ«: æ•°æ®ç§‘å­¦å®¶ | æ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d')}\n")
        self.render_overview()
        self.render_product_efficiency()
        self.render_pricing_efficiency()
        self.render_spatio_temporal()
        self.render_basket()
        return "\n".join(self.lines)

class GlobalStrategicReporter(StrategicReporter):
    def __init__(self, channel_name, global_data, all_channels_data, benchmarks):
        super().__init__(channel_name, global_data, benchmarks)
        self.all_channels = all_channels_data

    def generate(self):
        self.lines.append("# å…¨æ¸ é“ç»è¥å¤§ç›˜æ€»è§ˆ (Global Overview)\n")
        self.lines.append(f"> è¯Šæ–­çº§åˆ«: ç»è¥ä¸“å®¶ | æ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d')}\n")
        self.render_overview()
        self.render_channel_efficiency_matrix()
        self.render_channel_product_matrix()
        self.render_global_product_efficiency()
        return "\n".join(self.lines)

    def render_channel_efficiency_matrix(self):
        ce = self.data['channel_efficiency']
        rank = ce['rankings']
        self.add_header("2. æ¸ é“æ•ˆç‡å‘ˆç° (Channel Matrix)", 2)
        channels = sorted(rank['gmv_share'].keys(), key=lambda x: rank['gmv_share'][x], reverse=True)
        rows = []
        for ch in channels:
            row = [
                ch, fmt_p(rank['gmv_share'][ch]), fmt_c(rank['aov'][ch]), 
                fmt_f(rank['upt'][ch]), fmt_p(rank['discount_rate'][ch]), 
                fmt_p(rank['promo_penetration'][ch]), ce['ecological_niche'].get(ch, '-')
            ]
            rows.append(row)
        self.add_table(["æ¸ é“", "GMVè´¡çŒ®", "å®¢å•ä»·", "å®¢ä»¶æ•°", "æŠ˜æ‰£ç‡", "ä¿ƒé”€æ¸—é€", "ç”Ÿæ€ä½åˆ¤å®š"], rows)
        
        pb = ce['price_bands']
        bands = list(next(iter(pb.values())).keys()) if pb else []
        self.add_header("2.2 æ¸ é“ä»·æ ¼å¸¦åˆ†å¸ƒå¯¹æ¯”", 3)
        rows_pb = []
        for ch in channels:
            if ch in pb: rows_pb.append([ch] + [fmt_p(pb[ch].get(b, 0)) for b in bands])
        self.add_table(["æ¸ é“"] + bands, rows_pb)

    def render_channel_product_matrix(self):
        self.add_header("2.3 æ¸ é“å•†å“é©±åŠ¨åŠ›å¯¹æ¯”é€è§†", 3)
        rows = []
        for ch_name, ch_data in self.all_channels.items():
            r = ch_data.get('product_rankings', {})
            if not r: continue
            fmt_sku = lambda d: "<br>".join([f"{k} ({fmt_c(v)})" for k,v in list(d.items())[:3]])
            rows.append([ch_name, fmt_sku(r.get('top_10_gmv', {})), fmt_sku(r.get('top_10_qty', {})), fmt_sku(r.get('bottom_10_gmv', {}))])
        self.add_table(["æ¸ é“", "GMV Top 3", "é”€é‡ Top 3", "é•¿å°¾ Bottom 3"], rows)

    def render_global_product_efficiency(self):
        ce = self.data['channel_efficiency']
        self.add_header("3. å…¨ç½‘å•†å“æ•ˆç‡ (Global Top/Bottom)", 2)
        top10 = ce.get('global_top_10_gmv', {})
        self.add_table(["å•†å“åç§°", "é”€å”®é‡‘é¢ (GMV)"], [[k, fmt_c(v)] for k, v in top10.items()])

def get_report_html(title, md_content):
    import markdown
    html = markdown.markdown(md_content, extensions=['tables'])
    css = "<style>body{font-family:sans-serif;max-width:1000px;margin:40px auto;padding:20px;line-height:1.6;color:#24292e;background:#f6f8fa}.container{background:white;padding:40px;border-radius:8px;box-shadow:0 1px 3px rgba(0,0,0,0.12)}h1,h2,h3{border-bottom:1px solid #eaecef;padding-bottom:0.3em}table{border-collapse:collapse;width:100%;margin:20px 0}th,td{border:1px solid #dfe2e5;padding:10px;text-align:left}th{background:#f6f8fa}blockquote{border-left:4px solid #0366d6;background:#f1f8ff;padding:15px;margin:20px 0}</style>"
    return f"<html><head><meta charset='utf-8'><title>{title}</title>{css}</head><body><div class='container'>{html}</div></body></html>"

def main():
    base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    json_path = os.path.join(base_dir, "reports", "data", "analysis_v4_full.json")
    output_dir = os.path.join(base_dir, "reports", "diagnostics_v5")
    if not os.path.exists(output_dir): os.makedirs(output_dir)
    with open(json_path, 'r') as f: full_data = json.load(f)
    gb = full_data['global']['business_overview']
    benchmarks = {"aov_avg": gb['aov'], "upt_avg": gb['upt']}
    
    print("Generating Global Report...")
    global_rep = GlobalStrategicReporter("å…¨æ¸ é“æ€»è§ˆ", full_data['global'], full_data['channels'], benchmarks)
    md = global_rep.generate()
    with open(os.path.join(output_dir, "report_global_v4.md"), 'w') as f: f.write(md)
    with open(os.path.join(output_dir, "report_global_v4.html"), 'w') as f: f.write(get_report_html("Global Overview", md))
    
    for ch, data in full_data['channels'].items():
        print(f"Generating Detailed Report for {ch}...")
        rep = StrategicReporter(ch, data, benchmarks)
        md_text = reporter_md = rep.generate()
        with open(os.path.join(output_dir, f"report_{ch}_v4.md"), 'w') as f: f.write(md_text)
        with open(os.path.join(output_dir, f"report_{ch}_v4.html"), 'w') as f: f.write(get_report_html(ch, md_text))

if __name__ == "__main__":
    main()