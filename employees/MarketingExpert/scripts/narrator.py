import json
import os
import pandas as pd

class InsightNarrator:
    def __init__(self, report_dir: str, store_name: str):
        self.report_dir = report_dir
        self.store_name = store_name
        self.metrics_data = None
        self.new_old_attr = None
        self.profile_attr = None
        self._load_data()

    def _load_data(self):
        """Loads the three JSON report files."""
        try:
            # --- Load Core Metrics ---
            # This is tricky because the JSON is just an array. We rely on the known execution order.
            # (ä¸Šæµ·æ¹¾, Conversion), (ä¸Šæµ·æ¹¾, Duration), (ä¸Šæµ·æ¹¾, Dwell), (ä¸Šæµ·æ¹¾, POS_Buyers), (ä¸Šæµ·æ¹¾, Traffic)
            # (æ–°æ±Ÿæ¹¾, Conversion), ...
            store_map = {
                'ä¸Šæµ·æ¹¾': {'start': 0, 'metrics': ['Conversion', 'Duration', 'Dwell', 'POS_Buyers', 'Traffic']},
                'æ–°æ±Ÿæ¹¾': {'start': 5, 'metrics': ['Conversion', 'Duration', 'Dwell', 'POS_Buyers', 'Traffic']}
            }
            if self.store_name in store_map:
                with open(os.path.join(self.report_dir, 'advanced_analysis_results.json'), 'r', encoding='utf-8') as f:
                    all_metrics = json.load(f)
                
                self.metrics_data = {}
                store_info = store_map[self.store_name]
                for i, metric_name in enumerate(store_info['metrics']):
                    record = all_metrics[store_info['start'] + i]
                    # Add metric name to the record for easier lookup
                    record['æŒ‡æ ‡åç§°'] = metric_name
                    self.metrics_data[metric_name] = record
            
            # --- Load Attribution Data ---
            # These files should contain 'é—¨åº—åç§°' and can be filtered.
            attr_new_old_path = os.path.join(self.report_dir, 'attribution_new_old_customer.json')
            if os.path.exists(attr_new_old_path):
                with open(attr_new_old_path, 'r', encoding='utf-8') as f:
                    self.new_old_attr = pd.DataFrame(json.load(f))

            attr_profile_path = os.path.join(self.report_dir, 'attribution_customer_profile.json')
            if os.path.exists(attr_profile_path):
                with open(attr_profile_path, 'r', encoding='utf-8') as f:
                    self.profile_attr = pd.DataFrame(json.load(f))

        except FileNotFoundError as e:
            print(f"Error: Could not find a report file. {e}")
            raise
        except Exception as e:
            print(f"Error loading or parsing report files: {e}")
            raise
            
    def _format_metrics_table(self):
        """Formats the main metrics table from the new analysis results."""
        if not self.metrics_data:
            return "æ ¸å¿ƒæŒ‡æ ‡æ•°æ®ç¼ºå¤±ã€‚"

        header = "| æŒ‡æ ‡ (Metric) | ç»å¯¹å€¼å˜åŒ– (é—¨åº—) | è¶‹åŠ¿å˜åŒ– (é—¨åº—) | è¶…é¢ç»å¯¹å€¼å˜åŒ– (Alpha) | å½’ä¸€åŒ–è¶‹åŠ¿åˆ¤å®š |"
        sep =    "| :--- | :---: | :---: | :---: | :---: |"
        rows = []
        
        # Iterate in a fixed order for consistency
        for m_name in ['Traffic', 'POS_Buyers', 'Conversion', 'Duration', 'Dwell']:
            if m_name not in self.metrics_data:
                continue
            
            data = self.metrics_data[m_name]
            
            def fmt(val, prec=2):
                return f"{val:.{prec}f}" if isinstance(val, (int, float)) else str(val)

            row = (f"| **{m_name}** | "
                   f"{fmt(data.get('é—¨åº—_ç»å¯¹å€¼å˜åŒ–'))} | "
                   f"{fmt(data.get('é—¨åº—_è¶‹åŠ¿å˜åŒ–'))} | "
                   f"{fmt(data.get('è¶…é¢_ç»å¯¹å€¼å˜åŒ–'))} | "
                   f"{data.get('å½’ä¸€åŒ–è¶‹åŠ¿åˆ¤å®š', 'N/A')} |")
            rows.append(row)
            
        return "\n".join([header, sep] + rows)

    def _format_attribution_table(self, df: pd.DataFrame, comp_type: str, title: str):
        """Formats an attribution table (either new/old or profile)."""
        rows = [f"**{title}**:", ""]
        if df is None or df.empty or 'é—¨åº—åç§°' not in df.columns:
             rows.append(f"æ— æ³•ä¸º {self.store_name} ç”Ÿæˆ {title} å½’å› çœ‹æ¿ (æ•°æ®ç¼ºå¤±æˆ–æ ¼å¼é”™è¯¯)ã€‚")
             return "\n".join(rows)

        # The attribution files might not have the 'å¯¹æ¯”ç±»å‹' column, so we work with what we have.
        store_df = df[df['é—¨åº—åç§°'] == self.store_name].copy()
        if 'å¯¹æ¯”ç±»å‹' in store_df.columns:
            store_df = store_df[store_df['å¯¹æ¯”ç±»å‹'] == comp_type]

        if store_df.empty:
            rows.append(f"{self.store_name} çš„ {title} å½’å› æ•°æ® ({comp_type}) æœªæ‰¾åˆ°ã€‚")
            return "\n".join(rows)
            
        store_df = store_df.sort_values('ç»å¯¹å€¼å˜åŒ–', ascending=False)
        
        gainers = store_df[store_df['ç»å¯¹å€¼å˜åŒ–'] > 0].head(3)
        losers = store_df[store_df['ç»å¯¹å€¼å˜åŒ–'] < 0].tail(3)

        table = ["| äººç¾¤ (Segment) | å˜åŠ¨æ–¹å‘ | ç»å¯¹å¢å‡äººæ•° (Net Change) |",
                 "| :--- | :--- | :--- |"]
        for _, g in gainers.iterrows():
            table.append(f"| **{g['äººç¾¤æ ‡ç­¾']}** | ğŸŸ¢ æ–°å¢ | +{g['ç»å¯¹å€¼å˜åŒ–']:.0f} |")
        for _, l in losers.iterrows():
            table.append(f"| **{l['äººç¾¤æ ‡ç­¾']}** | ğŸ”´ æµå¤± | {l['ç»å¯¹å€¼å˜åŒ–']:.0f} |")
        
        if len(gainers) == 0 and len(losers) == 0:
            rows.append("æœªå‘ç°æ˜¾è‘—çš„äººç¾¤æ•°é‡å˜åŒ–ã€‚")
        else:
            rows.extend(table)

        return "\n".join(rows)

    def generate_prompt(self, output_prompt_file):
        """Generates the full narrative prompt from the loaded V2 data."""
        if not self.metrics_data:
            print("é”™è¯¯: æ ¸å¿ƒæŒ‡æ ‡æ•°æ®æœªèƒ½åŠ è½½ï¼Œæ— æ³•ç”Ÿæˆpromptã€‚")
            return
            
        # Extract basic info from the first available metric
        any_metric = next(iter(self.metrics_data.values()))
        reno_month = any_metric.get('reno_month', 'N/A')
        
        prompt = ["# Role: èµ„æ·±é›¶å”®æ•°æ®æˆ˜ç•¥ä¸“å®¶", "\n## ä»»åŠ¡: æ’°å†™ä¸€ä»½ã€æ•™ç§‘ä¹¦çº§ã€‘çš„å•åº—æ·±åº¦å®¡è®¡æŠ¥å‘Šã€‚"]
        prompt.append(f"\n# ã€{self.store_name}ã€‘ å…¨ç»´åº¦æ·±åº¦å®¡è®¡ (Anchor: {reno_month})")
        
        # --- æ¨¡å— 1: å¼‚å¸¸å¤ç›˜ ---
        prompt.append("\n## ç¬¬ä¸€éƒ¨åˆ†ï¼šå†å²å¼‚å¸¸å¤ç›˜ (Anomaly Review)")
        prompt.append("**1. åˆ†ææ€è·¯ (Why)**: è¯†åˆ«å†å²æ•°æ®ä¸­çš„â€œå™ªéŸ³â€èƒ½é˜²æ­¢åŸºæ•°åå·®è¯¯å¯¼ç»“è®ºã€‚")
        prompt.append("**2. æ•°æ®çœ‹æ¿ (Dashboard)**:")
        prompt.append("- *V2åˆ†ææµç¨‹ç›®å‰ä¸åŒ…å«ç‹¬ç«‹çš„å¼‚å¸¸ç‚¹æ£€æµ‹æ¨¡å—ã€‚*")
        prompt.append("\n> **æ·±åº¦è§£è¯»æŒ‡ä»¤**: è¯·åŸºäºä¸‹æ–¹æ ¸å¿ƒæŒ‡æ ‡çš„è¶‹åŠ¿å˜åŒ–ï¼Œåˆ¤æ–­æ˜¯å¦å­˜åœ¨æ½œåœ¨çš„åŸºæ•°æ•ˆåº”ï¼Ÿ")

        # --- æ¨¡å— 2: è¶‹åŠ¿ä¸æ•ˆèƒ½è¯Šæ–­ ---
        prompt.append("\n## ç¬¬äºŒéƒ¨åˆ†ï¼šè¶‹åŠ¿ä¸æ•ˆèƒ½è¯Šæ–­ (Trend & Efficiency)")
        prompt.append("**1. åˆ†ææ€è·¯ (Why)**: æˆ‘ä»¬é€šè¿‡â€œé—¨åº—è‡ªèº« vs. å¸‚åœºå¤§ç›˜â€çš„åŒé‡è§†è§’ï¼Œç»“åˆç»å¯¹å€¼å’Œè¶‹åŠ¿æ–œç‡ä¸¤ä¸ªç»´åº¦ï¼Œæ¥è¯„ä¼°æ”¹é€ çš„çœŸå®å¾—å¤±ã€‚")
        prompt.append("**2. æ ¸å¿ƒæŒ‡æ ‡è¯´æ˜ (Definitions)**:")
        prompt.append("- **ç»å¯¹å€¼å˜åŒ–**: æ”¹é€ åå‡å€¼ - æ”¹é€ å‰å‡å€¼ã€‚åæ˜ åŸºç¡€ç›˜çš„æŠ¬å‡æˆ–ä¸‹é™ã€‚")
        prompt.append("- **è¶‹åŠ¿å˜åŒ–**: æ”¹é€ åæ–œç‡ - æ”¹é€ å‰æ–œç‡ã€‚åæ˜ å¢é•¿â€œåŠ é€Ÿåº¦â€çš„å˜åŒ–ã€‚")
        prompt.append("- **è¶…é¢ç»å¯¹å€¼å˜åŒ– (Alpha)**: é—¨åº—ç»å¯¹å€¼å˜åŒ– - å¤§ç›˜ç»å¯¹å€¼å˜åŒ–ã€‚å‰¥ç¦»å¸‚åœºå½±å“åçš„çœŸå®æ•ˆæœã€‚")
        prompt.append("- **å½’ä¸€åŒ–è¶‹åŠ¿åˆ¤å®š**: åŸºäºé—¨åº—ä¸å¤§ç›˜çš„YoYå¢é€Ÿå·®(YoY Gap)çš„è¶‹åŠ¿åˆ¤å®šã€‚åæ˜ ç›¸å¯¹ç«äº‰åŠ›çš„å˜åŒ–è¶‹åŠ¿ã€‚")
        
        prompt.append("**3. æ•°æ®çœ‹æ¿ (Dashboard)**:")
        table = self._format_metrics_table()
        prompt.append(table)
        
        prompt.append("\n> **æ·±åº¦è§£è¯»æŒ‡ä»¤**:")
        prompt.append("- **æ ¸å¿ƒçŸ›ç›¾**: `è¶…é¢ç»å¯¹å€¼å˜åŒ–`ä¸ºæ­£ï¼Œä½†`å½’ä¸€åŒ–è¶‹åŠ¿åˆ¤å®š`ä¸ºâ€œæ¶åŒ–â€ï¼Œè¿™æ„å‘³ç€ä»€ä¹ˆï¼Ÿï¼ˆæç¤ºï¼šå¯èƒ½æ„å‘³ç€è™½ç„¶çŸ­æœŸè·‘èµ¢å¤§ç›˜ï¼Œä½†é¢†å…ˆçš„â€œåŠ é€Ÿåº¦â€æ­£åœ¨æ”¾ç¼“ï¼Œç›¸å¯¹ä¼˜åŠ¿åœ¨ç¼©å°ï¼‰ã€‚")
        prompt.append("- **é‡ä»·å…³ç³»**: ç»“åˆå®¢æµ(Traffic)å’Œä¹°å®¶æ•°(POS_Buyers)çš„å˜åŒ–ï¼Œåˆ¤æ–­æ˜¯â€œé‡ä»·é½å‡â€è¿˜æ˜¯â€œç¼©é‡æä»·â€ï¼Ÿ")

        # --- æ¨¡å— 3: ç»“æ„å½’å›  ---
        prompt.append("\n## ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®¢ç¾¤ç»“æ„å½’å›  (Structural Attribution)")
        prompt.append("**1. åˆ†ææ€è·¯ (Why)**: æ€»é‡çš„å˜åŒ–æ˜¯ç”±å“ªäº›å…·ä½“äººç¾¤é©±åŠ¨çš„ï¼Ÿæˆ‘ä»¬åšæŒä½¿ç”¨ **â€œç»å¯¹å€¼ (Headcount)â€** è¿›è¡Œå½’å› ã€‚")

        # --- New Robust Attribution Logic ---
        # Try for 'å¹´å†…å¯¹æ¯”' first, if it fails (returns a "not found" message), fall back to 'åŒæ¯”ä½è¯'.
        
        # New vs Old Customers
        new_old_table_content = self._format_attribution_table(self.new_old_attr, 'å¹´å†…å¯¹æ¯”', "æ•°æ®çœ‹æ¿ (Dashboard) - æ–°è€å®¢")
        if "æœªæ‰¾åˆ°" in new_old_table_content:
            new_old_table_content = self._format_attribution_table(self.new_old_attr, 'åŒæ¯”ä½è¯', "æ•°æ®çœ‹æ¿ (Dashboard) - æ–°è€å®¢ (åŒæ¯”ä½è¯)")
        prompt.append(new_old_table_content)

        # Customer Profiles
        profile_table_content = self._format_attribution_table(self.profile_attr, 'å¹´å†…å¯¹æ¯”', "æ•°æ®çœ‹æ¿ (Dashboard) - äººç¾¤ç”»åƒ")
        if "æœªæ‰¾åˆ°" in profile_table_content:
            profile_table_content = self._format_attribution_table(self.profile_attr, 'åŒæ¯”ä½è¯', "æ•°æ®çœ‹æ¿ (Dashboard) - äººç¾¤ç”»åƒ (åŒæ¯”ä½è¯)")
        prompt.append("\n" + profile_table_content)
        
        prompt.append("\n> **æ·±åº¦è§£è¯»æŒ‡ä»¤**: ç»“åˆå‰é¢çš„æ•ˆèƒ½æ•°æ®ï¼Œåˆ†æè¿™ç§å®¢ç¾¤ç½®æ¢æ˜¯â€œè‰¯æ€§æ¢è¡€â€ï¼ˆå¦‚é«˜ä»·å€¼å®¢ç¾¤æ›¿æ¢äº†ä½ä»·å€¼å®¢ç¾¤ï¼‰è¿˜æ˜¯â€œæ¶æ€§æµå¤±â€ï¼Ÿ")

        with open(output_prompt_file, 'w', encoding='utf-8') as f:
            f.write("\n".join(prompt))
        print(f"V2 Prompt Generated: {output_prompt_file}")


if __name__ == "__main__":
    # Example of how to run this new narrator
    try:
        # Define the target store and report directory
        target_store_name = 'ä¸Šæµ·æ¹¾'
        reports_directory = 'data-analysis/reports'
        output_file = os.path.join(reports_directory, f'prompt_for_{target_store_name}.md')

        # Initialize and run
        narrator = InsightNarrator(report_dir=reports_directory, store_name=target_store_name)
        narrator.generate_prompt(output_prompt_file=output_file)
    except Exception as e:
        print(f"An error occurred during prompt generation: {e}")
